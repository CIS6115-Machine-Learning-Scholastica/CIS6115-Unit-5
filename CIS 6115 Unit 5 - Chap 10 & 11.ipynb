{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate cANcer graDe Assessment (PANDA) Challenge\n",
    "\n",
    "This notebook will be used by the CIS 6115 students for Unit 5. \n",
    "\n",
    "Start by reading about the [Prostate cANcer graDe Assessment (PANDA) Challenge](https://www.kaggle.com/c/prostate-cancer-grade-assessment) in Kaggle. It is often good to read the top voted notebooks for the challenge also, which is Rohit Singh's [PANDA - EDA + Better Visualization+Simple Baseline](https://www.kaggle.com/rohitsingh9990/panda-eda-better-visualization-simple-baseline). This notebook is actually based on [PANDA DenseNet Keras Starter GPU](https://www.kaggle.com/yeayates21/panda-densenet-keras-starter-gpu) by Matt Yates\n",
    "\n",
    "## Chapter 10 & 11 \n",
    "\n",
    "- Chapter 10: Introduction to Artificial Neural Networks with Keras - Part 2\n",
    "- Chapter 11: Training Deep Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Writeup\n",
    "\n",
    "Use the the [Unit 5 Writeup](https://docs.google.com/document/d/1SytQJv4XEn67uc9c4IVcsJb_neW4F1y4LZAVQh6WBLY/edit?usp=sharing) to answer the questions posed in this notebook****\n",
    "\n",
    "## Walkthrough Video\n",
    "​\n",
    "Watch the [Unit 5 Walkthough Video by Tom](https://youtu.be/A5Oh95Yfw1E)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Python tools\n",
    "\n",
    "We'll use three libraries for this tutorial: \n",
    "- [pandas](http://pandas.pydata.org/) : dataframes for spreadsheet-like data analysis, reading CSV files, time series\n",
    "- [numpy](http://www.numpy.org/) : for multidimensional data and linear algebra tools\n",
    "- [matplotlib](http://matplotlib.org/) : Simple plotting and graphing\n",
    "- [seaborn](http://stanford.edu/~mwaskom/software/seaborn/) : more advanced graphing\n",
    "- [scikit-learn](https://scikit-learn.org/stable/) : provides many machine learning algorithms and tools to training and test.\n",
    "- [tensorflow](https://www.tensorflow.org/) : Google's backend library for neural networks and other machine learning\n",
    "- [keras](https://keras.io/) : High level machine learning API that we run on top of Tensorflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-098a8b2f1365>, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-098a8b2f1365>\"\u001b[1;36m, line \u001b[1;32m40\u001b[0m\n\u001b[1;33m    import openslide-python\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# First, we'll import pandas and numpy, two data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We'll also import seaborn and matplot, twp Python graphing libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import the needed sklearn libraries\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# The Keras library provides support for neural networks and deep learning\n",
    "# Use the updated Keras library from Tensorflow -- provides support for neural networks and deep learning\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Lambda, Flatten, LSTM, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, Convolution2D, MaxPooling2D, Flatten, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from keras.utils import np_utils\n",
    "AUTO = tf.data.experimental.AUTOTUNE          # Needed for tensorflow image operations\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "# There are two ways to load the data from the PANDA dataset:\n",
    "# Option 1: Load images using openslide\n",
    "#import openslide\n",
    "import openslide-python\n",
    "\n",
    "# Option 2: Load images using skimage (requires that tifffile is installed)\n",
    "#import skimage.io\n",
    "#import skimage\n",
    "from skimage import io\n",
    "\n",
    "# We will turn off some warns in this notebook to make it easier to read for new students\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print (\"Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the GPU or TPU\n",
    "\n",
    "For an good overview of GPUs and TPUs in machine learning, read [Central Processing Unit (CPU) vs Graphics Processing Unit (GPU) vs Tensor Processing Unit (TPU](https://iq.opengenus.org/cpu-vs-gpu-vs-tpu/)) from opengenus.org\n",
    "\n",
    "To enable the GPU, select it as the accelerator from the setting on the right-side panel.\n",
    "\n",
    "## Task 1: What is a GPU and a TPU\n",
    "\n",
    "Answer the following questions in the [Unit 5 Writeup](https://docs.google.com/document/d/1SytQJv4XEn67uc9c4IVcsJb_neW4F1y4LZAVQh6WBLY/edit?usp=sharing).\n",
    "\n",
    "### Question 1.1: GPU vs TPU\n",
    "\n",
    "In your own words, describe how a GPU is different from a CPU. Then describe what a TPU is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 36 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 20\n",
    "# Data access\n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target & ID Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\n",
    "test_df = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n",
    "print(\"Size of training data : \", train_df.shape)\n",
    "print(\"Size of testing data : \",test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is where the size of the images is set. Default is 224x224\n",
    "\n",
    "def preprocess_image(image_path, desired_size=224):\n",
    "    biopsy = openslide.OpenSlide(image_path)\n",
    "    im = np.array(biopsy.get_thumbnail(size=(desired_size,desired_size)))\n",
    "    im = Image.fromarray(im)\n",
    "    im = im.resize((desired_size,desired_size)) \n",
    "    im = np.array(im) / 255\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set number of images to process\n",
    "\n",
    "The code below loads in the images. Since this can take many minutes, the initial code only reads in 500 of the 10,000+ image available. You should comment out the line \n",
    "> N = 500\n",
    "\n",
    "and uncomment the line \n",
    "> N = train_df.shape[0]  \n",
    "\n",
    "to use all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This could take some time, so show the progress time\n",
    "\n",
    "\n",
    "# get the number of training images from the target\\id dataset\n",
    "N = 5000                     # ===== Use only 500 images to test the model\n",
    "#N = train_df.shape[0]     # ===== This to run on all data\n",
    "print (\"Running with a sample of the images with N = \", N)\n",
    "\n",
    "# create an empty matrix for storing the images\n",
    "x_train = np.empty((N, 224, 224, 3), dtype=np.float32)\n",
    "# loop through the images from the images ids from the target\\id dataset\n",
    "# then grab the cooresponding image from disk, pre-process, and store in matrix in memory\n",
    "for i, image_id in enumerate(tqdm(train_df['image_id'])):\n",
    "    x_train[i, :, :, :] = preprocess_image(\n",
    "        f'../input/prostate-cancer-grade-assessment/train_images/{image_id}.tiff'\n",
    "    )\n",
    "    # if sampling\n",
    "    if i >= N-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing the target (i.e. one-hot encoding the target)\n",
    "y_train = pd.get_dummies(train_df['isup_grade']).values.astype(np.int32)[0:N]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Size of training input : \", x_train.shape)\n",
    "print(\"Size of training output : \",y_train.shape)\n",
    "if os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n",
    "    print(\"Size of test input : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    test_size=0.20, \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Image Augmentation Generator\n",
    "\n",
    "We discuss options for image augmentation in this week's mini-project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify data_augment to change how training images are adjusted during training\n",
    "# See tf.image for documentation -- https://www.tensorflow.org/api_docs/python/tf/image\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)             # Cast  \n",
    "#    image = tf.image.random_flip_left_right(image)\n",
    "#    image = tf.image.random_flip_up_down(image)\n",
    "#    image = tf.image.random_brightness(image, 0.1)\n",
    "#    image = tf.image.random_contrast(image, 0.9, 1.0)\n",
    "#    image = tf.image.random_hue(image, 0.1)\n",
    "#    image = tf.image.random_contrast(image, 0.1)\n",
    "#    image = tf.image.random_saturation(image, 0.9, 1.0)\n",
    "#    image = tf.image.random_jpeg_quality(image, 85, 100)\n",
    "\n",
    "    #width = INPUT_SHAPE[0]\n",
    "    # These next four lines will randomly crop the images\n",
    "    #large_width = math.floor(width * 1.2)                                        # increase images sizes by 10% before random crop\n",
    "    #print (\"image width = \", width, \" resized to \", large_width)\n",
    "    #image = tf.image.resize(image, [large_width, large_width])\n",
    "    #image = tf.image.random_crop(image, [width, width, 3])\n",
    "    \n",
    "    #image = tf.image.random_saturation(image, 0, 2)\n",
    "    #image = tf.clip_by_value(image, clip_value_min=0., clip_value_max=1.)      # Change the values from 0-255 to 0.0-1.0\n",
    "    return image, label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_train, y_train))\n",
    "    .repeat()                                  # the training dataset must repeat for several epochs\n",
    "#    .shuffle(2048)                            # put images in random order\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_val, y_val))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model\n",
    "\n",
    "## Reusing Pretrained Layers\n",
    "From *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems*, 2nd Edition by Aurélien Géron, ISBN-13: 978-1492032649 \n",
    "\n",
    "> It is generally not a good idea to train a very large DNN from scratch: instead, you\n",
    "should always try to find an existing neural network that accomplishes a similar task\n",
    "to the one you are trying to tackle,... \n",
    "then reuse the lower layers of this network. This technique is called transfer learning. (page 345)\n",
    "\n",
    "## Task 2: Using a Pretrained Model\n",
    "\n",
    "Answer the following questions in the [Unit 5 Writeup](https://docs.google.com/document/d/1SytQJv4XEn67uc9c4IVcsJb_neW4F1y4LZAVQh6WBLY/edit?usp=sharing).\n",
    "\n",
    "### Question 1.2: Using Pretrained Models\n",
    "\n",
    "Review the four methods below that each create a NN model. Describe which use pre-trained models. Is just the network structure used or are pretrained weights loaded also? Finally, what does the following line determine:\n",
    "> pretrained_model.trainable = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224,224,3)\n",
    "OUTPUT_SHAPE = 6\n",
    "\n",
    "def build_model_custom():\n",
    "\n",
    "    # Set up the Neural Network\n",
    "\n",
    "    NN = Sequential()\n",
    "    NN.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "    NN.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "    NN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    NN.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    NN.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    NN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    NN.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    NN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    NN.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    NN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    NN.add(Flatten())\n",
    "    NN.add(Dense(256, activation='relu'))\n",
    "    NN.add(Dense(OUTPUT_SHAPE, activation='softmax'))\n",
    "    #NN.add(Dense(OUTPUT_SHAPE, activation='sigmoid'))\n",
    "\n",
    "    print (\"Neural Network Model created\")\n",
    "    # NN.summary()\n",
    "    return NN\n",
    " \n",
    "def build_model_VGG(weight_setting='imagenet'):\n",
    "    # Set up the Neural Network   \n",
    "\n",
    "    # ==== VGG === works with 224x224 size images\n",
    "    #pretrained_model = tf.keras.applications.VGG16(weights=None, include_top=False ,input_shape=INPUT_SHAPE)         # Using random initial weights\n",
    "    pretrained_model = tf.keras.applications.VGG16(weights=weight_setting, include_top=False ,input_shape=INPUT_SHAPE)   # Using pretrained weights from Imagenet\n",
    "\n",
    "    # Set the model so that all the weights are trainable with the new whale images\n",
    "    pretrained_model.trainable = True      # False = transfer learning, True = fine-tuning\n",
    "\n",
    "    # Here the sample from page 461 of the textbook\n",
    "    model = Sequential([\n",
    "        pretrained_model,                                 # Include layers in pretrained model from above\n",
    "        GlobalAveragePooling2D(),\n",
    "        #Dense(1024, activation=\"relu\"),     # Can add optional additional layers here\n",
    "        #Dense(200, activation=\"relu\"),      # Can add optional additional layers here\n",
    "        Dense(OUTPUT_SHAPE, activation='softmax')\n",
    "        #Dense(OUTPUT_SHAPE, activation='sigmoid')\n",
    "    ])\n",
    "    print (\"Neural Network Model created\")\n",
    "    print (\"=== Pretrained Model =========================================================================\")\n",
    "    pretrained_model.summary()   # print layers in pretrained model\n",
    "    print (\"=== Final Model =========================================================================\")\n",
    "    model.summary()              # print final model\n",
    "    return model\n",
    "\n",
    "def build_model_Xception(weight_setting='imagenet'):    \n",
    "    # Set up the Neural Network   \n",
    "\n",
    "    # ==== Xception === \n",
    "    # by default Xception expects images of size 299x299 pixels\n",
    "    #pretrained_model = tf.keras.applications.Xception(weights=None, include_top=False ,input_shape=INPUT_SHAPE)            # Using random initial weights\n",
    "    pretrained_model = tf.keras.applications.Xception(weights=weight_setting, include_top=False ,input_shape=INPUT_SHAPE)      # Using pretrained weights from Imagenet\n",
    "\n",
    "    # Set the model so that all the weights are trainable with the new whale images\n",
    "    pretrained_model.trainable = True      # False = transfer learning, True = fine-tuning\n",
    "\n",
    "    # Here the sample from page 461 of the textbook\n",
    "    model = Sequential([\n",
    "        pretrained_model,                                 # Include layers in pretrained model from above\n",
    "        GlobalAveragePooling2D(),\n",
    "        #Dense(1024, activation=\"relu\"),     # Can add optional additional layers here\n",
    "        #Dense(200, activation=\"relu\"),      # Can add optional additional layers here\n",
    "        Dense(OUTPUT_SHAPE, activation='softmax')\n",
    "        #Dense(OUTPUT_SHAPE, activation='sigmoid')\n",
    "    ])\n",
    "    print (\"Neural Network Model created\")\n",
    "    print (\"=== Pretrained Model =========================================================================\")\n",
    "    pretrained_model.summary()   # print layers in pretrained model\n",
    "    print (\"=== Final Model =========================================================================\")\n",
    "    model.summary()              # print final model\n",
    "    return model\n",
    "\n",
    "def build_model_DenseNet():\n",
    "    densenet = DenseNet121(\n",
    "    weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    "    )\n",
    "    model = Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.50))\n",
    "    #model.add(Dense(6, activation='sigmoid'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    print (\"Neural Network Model created\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Models Using the Functional API\n",
    "\n",
    "The following inception model uses the functional API to define the model and is another illustration from the example shown in the textbook. This is the layout of a typical inception module--note that the connections are not sequential\n",
    "![](https://www.researchgate.net/profile/Bo_Zhao48/publication/312515254/figure/fig3/AS:489373281067012@1493687090916/nception-module-of-GoogLeNet-This-figure-is-from-the-original-paper-10.png)\n",
    "\n",
    "From *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems*, 2nd Edition by Aurélien Géron, ISBN-13: 978-1492032649 \n",
    "\n",
    "> Once you have built the Keras model, everything is exactly like earlier, so there’s no\n",
    "need to repeat it here: you must compile the model, train it, evaluate it, and use it to\n",
    "make predictions. (page 310)\n",
    "\n",
    "## Task 3: Keras Functional API\n",
    "\n",
    "Answer the following questions in the [Unit 5 Writeup](https://docs.google.com/document/d/1SytQJv4XEn67uc9c4IVcsJb_neW4F1y4LZAVQh6WBLY/edit?usp=sharing).\n",
    "\n",
    "### Question 1.3: Functional API \n",
    "\n",
    "The code below uses the functional API to build a network. Describe how the Functional API is different from the Sequential API. What are some times when the Functional API is needed over the Sequential API?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_Inception(): \n",
    "    input_img = Input(shape = INPUT_SHAPE)\n",
    "\n",
    "    pre_1 = Conv2D(64, (3,3), strides=(2,2), activation='relu', name='pre_1')(input_img)\n",
    "    pre_2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='pre_2')(pre_1)\n",
    "\n",
    "    #First Inception module\n",
    "    size = 32\n",
    "    incep_1_1x1_a = Conv2D(64, (1,1), padding='same', activation='relu', name='incep_1_1x1_a')(pre_2)\n",
    "    incep_1_1x1_b = Conv2D(96, (1,1), padding='same', activation='relu', name='incep_1_1x1_b')(pre_2)\n",
    "    incep_1_3x3_b = Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu', name='incep_1_3x3_b')(incep_1_1x1_b)\n",
    "    incep_1_1x1_c = Conv2D(16, (1,1), padding='same', activation='relu', name='incep_1_1x1_c')(pre_2)\n",
    "    incep_1_5x5_c = Convolution2D(32, (5,5), strides=(1,1), padding='same', activation='relu', name='incep_1_5x5_c')(incep_1_1x1_c)\n",
    "    incep_1_pool_d = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='incep_1_pool_d')(pre_2)\n",
    "    incep_1_1x1_d = Convolution2D(32, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_1_1x1_d')(incep_1_pool_d)\n",
    "\n",
    "    incep_1_output = concatenate([incep_1_1x1_a, incep_1_3x3_b, incep_1_5x5_c, incep_1_1x1_d], axis = 3, name='incep_1_output')\n",
    "\n",
    "\n",
    "    #Second Inception module\n",
    "    #size = 64\n",
    "    incep_2_1x1_a = Conv2D(128, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_2_1x1_a')(incep_1_output)\n",
    "    incep_2_1x1_b = Conv2D(128, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_2_1x1_b')(incep_1_output)\n",
    "    incep_2_3x3_b = Conv2D(192, (3,3), strides=(1,1), padding='same', activation='relu', name='incep_2_3x3_b')(incep_2_1x1_b)\n",
    "    incep_2_1x1_c = Conv2D(32, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_2_1x1_c')(incep_1_output)\n",
    "    incep_2_5x5_c = Convolution2D(96, (5,5), strides=(1,1), padding='same', activation='relu', name='incep_2_5x5_c')(incep_2_1x1_c)\n",
    "    incep_2_pool_d = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='incep_2_pool_d')(incep_1_output)\n",
    "    incep_2_1x1_d = Convolution2D(64, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_2_1x1_d')(incep_2_pool_d)\n",
    "\n",
    "    incep_2_output = concatenate([incep_2_1x1_a, incep_2_3x3_b, incep_2_5x5_c, incep_2_1x1_d], axis = 3, name='incep_2_output')\n",
    "    pool_2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"same\", name='pool_2')(incep_2_output)\n",
    "\n",
    "\n",
    "    #Third Inception module\n",
    "    #size = 64\n",
    "    incep_3_1x1_a = Conv2D(192, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_3_1x1_a')(pool_2)\n",
    "    incep_3_1x1_b = Conv2D(96, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_3_1x1_b')(pool_2)\n",
    "    incep_3_3x3_b = Conv2D(208, (3,3), strides=(1,1), padding='same', activation='relu', name='incep_3_3x3_b')(incep_3_1x1_b)\n",
    "    incep_3_1x1_c = Conv2D(16, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_3_1x1_c')(pool_2)\n",
    "    incep_3_5x5_c = Convolution2D(48, (5,5), strides=(1,1), padding='same', activation='relu', name='incep_3_5x5_c')(incep_3_1x1_c)\n",
    "    incep_3_pool_d = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding=\"same\", name='incep_3_pool_d')(pool_2)\n",
    "    incep_3_1x1_d = Convolution2D(64, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_3_1x1_d')(incep_3_pool_d)\n",
    "\n",
    "    incep_3_output = concatenate([incep_3_1x1_a, incep_3_3x3_b, incep_3_5x5_c, incep_3_1x1_d], axis = 3, name='incep_3_output')\n",
    "\n",
    "\n",
    "    #Fourth Inception module\n",
    "    #size = 128\n",
    "    incep_4_1x1_a = Conv2D(160, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_4_1x1_a')(incep_3_output)\n",
    "    incep_4_1x1_b = Conv2D(112, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_4_1x1_b')(incep_3_output)\n",
    "    incep_4_3x3_b = Conv2D(224, (3,3), strides=(1,1), padding='same', activation='relu', name='incep_4_3x3_b')(incep_4_1x1_b)\n",
    "    incep_4_1x1_c = Conv2D(24, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_4_1x1_c')(incep_3_output)\n",
    "    incep_4_5x5_c = Convolution2D(64, (5,5), strides=(1,1), padding='same', activation='relu', name='incep_4_5x5_c')(incep_4_1x1_c)\n",
    "    incep_4_pool_d = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding=\"same\", name='incep_4_pool_d')(incep_3_output)\n",
    "    incep_4_1x1_d = Convolution2D(64, (1,1), strides=(1,1), padding='same', activation='relu', name='incep_4_1x1_d')(incep_4_pool_d)\n",
    "\n",
    "    incep_4_output = concatenate([incep_4_1x1_a, incep_4_3x3_b, incep_4_5x5_c, incep_4_1x1_d], axis = 3, name='incep_4_output')\n",
    "    pool_3 = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='pool_5')(incep_3_output)\n",
    "\n",
    "    loss3_flat = AveragePooling2D(pool_size=(7,7), strides=(1,1))(pool_3)\n",
    "    loss4_flat = Flatten()(loss3_flat)\n",
    "\n",
    "    loss3_classifier_0 = Dense(1024, name='loss3_classifier_0', activation='relu')(loss4_flat)\n",
    "    loss3_classifier_act = Dense(200, name='loss3_classifier_act', activation=\"relu\")(loss3_classifier_0)\n",
    "    final_output = Dense(6, name='final_output', activation='sigmoid')(loss3_classifier_act)\n",
    "    model = Model(inputs = input_img, outputs = final_output)\n",
    "    print (\"Neural Network Model created\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Optimizers\n",
    "##  [RMSProp](https://keras.io/api/optimizers/rmsprop/)\n",
    "\n",
    "> As we’ve seen, AdaGrad runs the risk of slowing down a bit too fast and never con‐\n",
    "verging to the global optimum. The RMSProp algorithm16 fixes this by accumulating\n",
    "only the gradients from the most recent iterations (page 355)\n",
    "\n",
    "## [Adam](https://keras.io/api/optimizers/adam/)\n",
    "> Adam which stands for adaptive moment estimation, combines the ideas of momen‐\n",
    "tum optimization and RMSProp: just like momentum optimization, it keeps track of\n",
    "an exponentially decaying average of past gradients; and just like RMSProp, it keeps\n",
    "track of an exponentially decaying average of past squared gradients (page 356)\n",
    "\n",
    "## Task 4: Optimizers\n",
    "\n",
    "Answer the following questions in the [Unit 5 Writeup](https://docs.google.com/document/d/1SytQJv4XEn67uc9c4IVcsJb_neW4F1y4LZAVQh6WBLY/edit?usp=sharing).\n",
    "\n",
    "### Question 1.4: Functional API \n",
    "\n",
    "Read about RMSprop and Adam learning optimizers and how the adjust the learning weights as we train a network. Then select one of these to use below. Describe why you selected the one you did.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Optimizer === We will study these options in a future unit. For not, just leave as RMSprop\n",
    "# Some sample weight optimizer settings\n",
    "#RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "optimizer_RMSprop = RMSprop(lr=0.00001, epsilon=1e-08)\n",
    "#optimizer_Adam = Adam(learning_rate=0.001) # default learning rate\n",
    "optimizer_Adam = Adam(learning_rate=0.0001)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model_DenseNet()\n",
    "    #model = build_model_Inception()\n",
    "    #model = build_model_Xception('imagenet')\n",
    "    \n",
    "    model.compile(\n",
    "        # loss='binary_crossentropy',\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer_Adam,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "From Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, 2nd Edition by Aurélien Géron, ISBN-13: 978-1492032649\n",
    "\n",
    "> The fit() method accepts a callbacks argument that lets you specify a list of objects\n",
    "that Keras will call at the start and end of training, at the start and end of each epoch,\n",
    "and even before and after processing each batch. For example, the ModelCheckpoint\n",
    "callback saves checkpoints of your model at regular intervals during training, by\n",
    "default at the end of each epoch: (page 315)\n",
    "\n",
    "Here is the documentation of the callbacks:\n",
    "\n",
    "-  [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau). \n",
    "\n",
    "-  [EarlyStopping callback](https://keras.io/callbacks/#earlystopping) \n",
    "\n",
    "-  [ModelCheckpoint callback](https://keras.io/callbacks/#modelcheckpoint) \n",
    "\n",
    "## Task 5: Callbacks\n",
    "\n",
    "Answer the following questions in the [Unit 5 Writeup](https://docs.google.com/document/d/1SytQJv4XEn67uc9c4IVcsJb_neW4F1y4LZAVQh6WBLY/edit?usp=sharing).\n",
    "\n",
    "### Question 1.5: Callbacks \n",
    "\n",
    "Select one of the callbacks below and write a description of what it does and why we use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# reduce the learning rate by 50%. Make patience smaller to change the rate more often\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=5, \n",
    "                                            verbose=2, \n",
    "                                            factor=0.5,                                            \n",
    "                                            min_lr=0.000001)\n",
    "\n",
    "# Stop training if not improvement after a while. Make patience smaller to have model stop faster\n",
    "early_stops = EarlyStopping(monitor='val_loss', \n",
    "                            min_delta=0, \n",
    "                            patience=20, \n",
    "                            verbose=2, \n",
    "                            mode='auto')\n",
    "import datetime\n",
    "\n",
    "# Save the model. Saves only the best results and saves only the wieghts. \n",
    "# File name will include the epoch number and the validation accuracy\n",
    "checkpointer = ModelCheckpoint(filepath = 'cis6115_PANDA.{epoch:02d}-{accuracy:.6f}.hdf5',\n",
    "                               verbose=2,\n",
    "                               save_best_only=True, \n",
    "                               save_weights_only = True)\n",
    "\n",
    "# Set up Tensorboard to monitor the training progress\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard for Visualization\n",
    "From Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, 2nd Edition by Aurélien Géron, ISBN-13: 978-1492032649\n",
    "\n",
    "> TensorBoard is a great interactive visualization tool that you can use to view the\n",
    "learning curves during training, compare learning curves between multiple runs, vis‐\n",
    "ualize the computation graph, analyze training statistics, view images generated by\n",
    "your model, visualize complex multidimensional data projected down to 3D and\n",
    "automatically clustered for you, and more! This tool is installed automatically when\n",
    "you install TensorFlow, so you already have it. (page 317)\n",
    "\n",
    "I don't know if tensorboard will work in the Kaggle environment, so I have commented this code out for now. It should work in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %%tensorboard --logdir logs/scalars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Initially the epochs are only set to 20 to keep training time down. Later consider increasing this, particularly if you are using the early_stops callback which will stop training once it plateaus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    #callbacks=[learning_rate_reduction, early_stops, tensorboard_callback],\n",
    "    callbacks=[learning_rate_reduction, early_stops],\n",
    "    validation_data=valid_dataset,\n",
    "    #epochs=EPOCHS\n",
    "    epochs=20\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model\n",
    "\n",
    "From Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, 2nd Edition by Aurélien Géron, ISBN-13: 978-1492032649\n",
    "\n",
    "> Keras will use the HDF5 format to save both the model’s architecture (including every\n",
    "layer’s hyperparameters) and the values of all the model parameters for every layer\n",
    "(e.g., connection weights and biases). It also saves the optimizer (including its hyper‐\n",
    "parameters and any state it may have). (page 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code sample to save the model, including the weights, or just the weights\n",
    "# model.save(\"CIS6115_model.h5\")            # save the model structure\n",
    "# model.save_weights('CIS6115_weights.h5')  # always save your weights after training or during training\n",
    "\n",
    "#Code sample to load the saved model or just the model weights\n",
    "# ==== Generally this code should be at the beginning of the notebook once the model is define but before it is trained.\n",
    "# model = keras.models.load_model(\"CIS6115_model.h5\")\n",
    "# model.load_weights('CIS6115_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Training History\n",
    "We store the performance during training is a variable named 'history'. The x-axis is the training time or number of epochs.\n",
    "\n",
    "- Accuracy: Accuracy of the predictions, hopefully this is increasing to near 1.0\n",
    "- Loss: How close the output is to the desired output, this should decrease to near 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will display the loss and the accuracy of the model for each epoch\n",
    "# NOTE: this is a little fancy display than is shown in the textbook\n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    #ax.set_ylim(0.28,1.05)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])\n",
    "\n",
    "# We store the performance during training in a variable named 'history'. The x-axis is the training time or number of epochs.\n",
    "#    Accuracy: Accuracy of the predictions; hopefully this is increasing to near 1.0\n",
    "#    Loss: How close the output is to the desired output; this should decrease to near 0.0\n",
    "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)\n",
    "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Kaggle does not provide sample test images for running the notebook. These are only available once you submit your notebook for scoring. So, the code below checks if the test_images are available. If they are, we know we are doing an official submission, otherwise we fake it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the images from the images ids from the target\\id dataset\n",
    "# then grab the cooresponding image from disk, pre-process, and store in matrix in memory\n",
    "if os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n",
    "    print (\"Test images found\")\n",
    "    # do the same thing as the last cell but on the test\\holdout set\n",
    "    N = test_df.shape[0]\n",
    "    x_test = np.empty((N, 224, 224, 3), dtype=np.float32)\n",
    "    for i, image_id in enumerate(tqdm(test_df['image_id'])):\n",
    "        x_test[i, :, :, :] = preprocess_image(\n",
    "            f'../input/prostate-cancer-grade-assessment/test_images/{image_id}.tiff'\n",
    "        )\n",
    "        \n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(x_test)\n",
    "        .batch(BATCH_SIZE)\n",
    "    )\n",
    "else: \n",
    "    print (\"===== Problem ==== No test images found\")\n",
    "\n",
    "    \n",
    "sample_test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(x_train)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug code\n",
    "This is just some code I was using to debug the submission process. It should be removed enventually.\n",
    "\n",
    "y_sample = model.predict(sample_test_dataset)\n",
    "\n",
    "print (y_sample)\n",
    "print (type(y_sample))\n",
    "y_max = np.argmax(y_sample, axis=1)     # Select index with the highest probability for each test image\n",
    "print (y_max)\n",
    "print (train_df['isup_grade'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "if os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n",
    "    print (\"found test data\")\n",
    "    y_test = model.predict(test_dataset)\n",
    "    results = np.argmax(y_test, axis=1)     # Select index with the highest probability for each test image\n",
    "    test_df['isup_grade'] = results\n",
    "    test_df['isup_grade'] = test_df['isup_grade'].astype(int)\n",
    "    test_df.to_csv('submission.csv', index=False)\n",
    "else: # if test is not available, just submit some random values\n",
    "    print (\"No test data found, using some random values\")  \n",
    "    random.seed(42)\n",
    "    submission = pd.read_csv('../input/prostate-cancer-grade-assessment/sample_submission.csv')\n",
    "    results = np.random.randint(0,6,len(submission))\n",
    "    submission['isup_grade'] = results\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Improve this notebook\n",
    "\n",
    "## Mini-Project Writeup 1: Prostrate Cancer Challenge Summary\n",
    "Read about the [Prostate cANcer graDe Assessment (PANDA) Challenge](https://www.kaggle.com/c/prostate-cancer-grade-assessment) in Kaggle.\n",
    "\n",
    "Write a short summary of the challenge:\n",
    "\n",
    "- What is the goal of the challenge?\n",
    "- What types of images are provided?\n",
    "- What should the model predict? What is an ISUP grade?\n",
    "\n",
    "*Make sure you put this in your own words--do not just cut/paste from Kaggle*\n",
    "\n",
    "## Mini-Project Writeup 2: Image Augmentation\n",
    "\n",
    "In the code above, the `data_augment(image, label)` method can be used to modify the images during training. This uses the tensorflow methods such as \n",
    "> image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "See the tf.image for documentation -- https://www.tensorflow.org/api_docs/python/tf/image\n",
    "\n",
    "\n",
    "\n",
    "Implement some sort of image augmentation in your model by adjusting the `data_augment(image, label)` method. Train the network with this method and describe your results.\n",
    "\n",
    "*Feel free to post your results to the course discussion area.*\n",
    "\n",
    "Then review the first portion of Iafoss's notebook,[PANDA concat tile pooling starter](https://www.kaggle.com/iafoss/panda-concat-tile-pooling-starter-0-79-lb) and describe the image augmenation he suggests. \n",
    "\n",
    "# Mini-Project Writeup 3: Modify the Model \n",
    "\n",
    "Try at least one other adjustment to this notebook. This could include changing the network structure, learning epochs, optimizer, etc.\n",
    "\n",
    "Write a paragraph summarizing your results and analyze why you think they turned out the way they did."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
